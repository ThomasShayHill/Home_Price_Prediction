{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#Set up workspace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pysal\n",
    "import statsmodels.api as sm\n",
    "from pysal import W, lat2W\n",
    "from pysal.cg.kdtree import KDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomashill/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# read in data to use \n",
    "all_listings = pd.read_csv('All_Listings_geocoded.csv')\n",
    "sold_listings = pd.read_csv('Sold_Listings_geocoded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Suppress scientific notation\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "#Concatenate long and lat coordinates into a new column\n",
    "sold_listings['Coordinates'] = list(zip(sold_listings.DisplayX, sold_listings.DisplayY))\n",
    "\n",
    "#Add a PPSF column\n",
    "PPSF = sold_listings['SOLDPRICE']/sold_listings['SQFT']\n",
    "sold_listings = sold_listings.assign(PPSF = PPSF)\n",
    "\n",
    "#Get list of property types\n",
    "prop_types = np.unique(sold_listings['TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = sold_listings[sold_listings['YEAR_ORIG']==2016]\n",
    "df_2017 = sold_listings[sold_listings['YEAR_ORIG']==2017]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write a formula to find the PPSF of the k nearest neighbors of a given property\n",
    "\n",
    "def find_neighbors_point(point,dataframe,num_neighbors):\n",
    "    if len(dataframe)<1:\n",
    "        PPSFs = []\n",
    "        for neighbor in range(num_neighbors):\n",
    "            PPSFs.append(np.nan)\n",
    "    else:\n",
    "        coordinates = list(dataframe['Coordinates'])\n",
    "        tree = KDTree(coordinates, distance_metric='Arc', radius=pysal.cg.RADIUS_EARTH_KM)\n",
    "        dists,neibs = tree.query((point), k=num_neighbors)\n",
    "\n",
    "        PPSFs = []\n",
    "        for neighbor in neibs:\n",
    "            if np.isnan(neighbor):\n",
    "                PPSF_value = np.nan\n",
    "            else:\n",
    "                row = dataframe.iloc[[neighbor]]\n",
    "                PPSF_value = row['PPSF']\n",
    "                PPSF_value = PPSF_value.values[0]\n",
    "            PPSFs.append(PPSF_value)\n",
    "    neighbor_values = pd.DataFrame({\n",
    "        'PPSFs': PPSFs})\n",
    "    neighbor_values = neighbor_values.transpose()\n",
    "    \n",
    "    \n",
    "    return neighbor_values, dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Write a formula to find the k-nearest neighbors PPSF and dist for each point in an entire dataframe\n",
    "\n",
    "def find_neighbors_df(df,num_neighbors=50):\n",
    "    df_2016 = df[df['YEAR_ORIG']==2016]\n",
    "    df_2017 = df[df['YEAR_ORIG']==2017]\n",
    "\n",
    "    neighbor_PPSFs = []\n",
    "    neighbor_dists = []\n",
    "    for i in list(df_2017['Coordinates']):\n",
    "        neighbors,dists = find_neighbors_point(i,df_2016,num_neighbors)\n",
    "        neighbor_PPSFs.append(neighbors) \n",
    "        neighbor_dists.append(dists)\n",
    "    \n",
    "    added_columns = list(range(0, num_neighbors))\n",
    "    \n",
    "    added_columns_PPSF = [str(i)+'_PPSF' for i in added_columns]\n",
    "    added_columns_dist = [str(i)+'_Dist' for i in added_columns]\n",
    "    \n",
    "    neighbor_PPSF_df = pd.concat(neighbor_PPSFs)\n",
    "    neighbor_PPSF_df.columns = added_columns_PPSF\n",
    "    neighbor_PPSF_df = neighbor_PPSF_df.reset_index()\n",
    "    \n",
    "    neighbor_dist_df = pd.DataFrame(neighbor_dists)\n",
    "    neighbor_dist_df.columns = added_columns_dist\n",
    "    neighbor_dist_df = neighbor_dist_df.reset_index()\n",
    "        \n",
    "    df_2017 = df_2017.reset_index()\n",
    "    \n",
    "    df_2017 = pd.concat([df_2017,neighbor_PPSF_df,neighbor_dist_df],axis=1)\n",
    "    \n",
    "    return df_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above is a computationally intensive procedure. Since this is an O(n^2) operation, partition the dataset so that the calculation takes less time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MSA_cities = ['Abington',' Amesbury Town', 'Andover', 'Arlington', 'Ayer', \n",
    "              'Bellingham', 'Belmont', 'Beverly',' Boston', 'Boxford', 'Braintree Town', 'Bridgewater', 'Brockton', 'Brookline', 'Burlington',\n",
    "              'Cambridge', 'Chelsea', 'Cochituate', \n",
    "              'Danvers', 'Dedham', 'Dover', 'Duxbury', 'East Pepperell', 'Essex', 'Everett'\n",
    "              'Foxborough','Framingham','Franklin Town', 'Gloucester', 'Green Harbor-Cedar Crest', 'Groton',\n",
    "              'Hanson', 'Haverhill', 'Hingham', 'Holbrook', 'Hopkinton', 'Hudson', 'Hull',\n",
    "              'Ipswich',\"Kingston\",\n",
    "              'Lawrence','Lexington', 'Littleton Common', 'Lowell', 'Lynn', 'Lynnfield', \n",
    "              'Malden', 'Marblehead', 'Marion Center', 'Marlborough', 'Marshfield', 'Marshfield Hills', 'Mattapoisett Center', 'Maynard',\n",
    "              'Medfield','Medford','Melrose','Methuen Town','Middleborough Center','Millis-Clicquot','Milton',\n",
    "              'Nahant','Needham','Newburyport','Newton','North Lakeville','North Pembroke','North Plymouth','North Scituate','Norwood',\n",
    "              'Ocean Bluff-Brant Rock', 'Onset',\n",
    "              'Peabody', 'Pepperell', 'Pinehurst', 'Plymouth',\n",
    "              'Quincy',\n",
    "              'Randolph', 'Reading', 'Revere', 'Rockport', 'Rowley', \n",
    "              'Salem', 'Salisbury', 'Saugus', 'Scituate', 'Sharon', 'Shirley', 'Somerville', 'South Duxbury', 'Southfield', 'Stoneham', 'Swampscott',\n",
    "              'The Pinehills', 'Topsfield', 'Townsend', \n",
    "              'Wakefield', 'Walpole', 'Waltham', 'Wareham Center', 'Watertown Town', 'Wellesley', 'West Concord', 'West Wareham',\n",
    "              'Weweantic', 'Weymouth Town', 'White Island Shores', 'Wilmington', 'Winchester',  'Winthrop Town', 'Woburn']\n",
    "\n",
    "non_MSA_cities = list(set(list(np.unique(sold_listings['CITY']))) - set(MSA_cities))\n",
    "\n",
    "df_MSA = sold_listings.loc[sold_listings['CITY'].isin(MSA_cities)]\n",
    "df_non_MSA = sold_listings.loc[sold_listings['CITY'].isin(non_MSA_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_neighbors = 50\n",
    "\n",
    "full_type_dfs = []\n",
    "for prop_type in prop_types:\n",
    "    type_df = df_MSA[df_MSA['TYPE']==prop_type]\n",
    "    new_df = find_neighbors_df(type_df,num_neighbors)\n",
    "    full_type_dfs.append(new_df)\n",
    "MSA_neighbors_df_2017 = pd.concat(full_type_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_neighbors = 50\n",
    "\n",
    "full_type_dfs = []\n",
    "for prop_type in prop_types:\n",
    "    type_df = df_non_MSA[df_non_MSA['TYPE']==prop_type]\n",
    "    new_df = find_neighbors_df(type_df,num_neighbors)\n",
    "    full_type_dfs.append(new_df)\n",
    "non_MSA_neighbors_df_2017 = pd.concat(full_type_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors_df_2017 = pd.concat([MSA_neighbors_df_2017,non_MSA_neighbors_df_2017])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Replace the PPSF's with the predicted prices based on those PPSF's (i.e., PPSF*row property's SF)\n",
    "\n",
    "added_columns = list(range(0, num_neighbors))\n",
    "added_columns_PPSF = [str(i)+'_PPSF' for i in added_columns]\n",
    "\n",
    "for i in added_columns_PPSF:\n",
    "    predicted_price = neighbors_df_2017[i]*neighbors_df_2017['SQFT']\n",
    "    neighbors_df_2017[i] = predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save the above for future use\n",
    "neighbors_df_2017.to_csv(\"Neighbors_df_2017.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
